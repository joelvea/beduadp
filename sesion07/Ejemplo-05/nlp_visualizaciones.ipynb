{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "nlp_visualizaciones.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWX8gS0vdyj0"
      },
      "source": [
        "## Ejemplo 5: NLP y Visualizaciones\n",
        "\n",
        "### 1. Objetivos:\n",
        "    - Aprender qué visualizaciones podemos realizar de nuestros procesamientos de lenguaje natural\n",
        " \n",
        "---\n",
        "    \n",
        "### 2. Desarrollo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GTruoyPdyj1"
      },
      "source": [
        "Como ya bien sabes, las visualizaciones son una parte esencial de nuestros análisis. Vamos a aprender cómo realizar algunas visualizaciones de los análisis estadísticos que ya hemos realizado. Esto nos ayudará a presentar nuestros hallazgos de manera más efectiva."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJr1XedEdyj2"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vnL4p2vdyj3"
      },
      "source": [
        "df = pd.read_json('https://raw.githubusercontent.com/manu-msr/beduadp/master/Datasets/new_york_times_bestsellers-clean.json')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1a2oPHsdyj5"
      },
      "source": [
        "df['rank.numberInt'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9qSySmXdyj5"
      },
      "source": [
        "grouped_by_title = df.groupby('title')['description'].max()\n",
        "grouped_by_title = grouped_by_title.str.lower()\n",
        "grouped_by_title = grouped_by_title.str.strip()\n",
        "grouped_by_title = grouped_by_title.str.replace('[^\\w\\s]', '')\n",
        "grouped_by_title = grouped_by_title.str.replace('\\d', '')\n",
        "grouped_by_title = grouped_by_title.str.replace('\\\\n', '')\n",
        "grouped_by_title = grouped_by_title.dropna()\n",
        "\n",
        "tokenized = grouped_by_title.apply(nltk.word_tokenize)\n",
        "all_words = tokenized.sum()\n",
        "\n",
        "english_stop_words = stopwords.words('english')\n",
        "all_words_except_stop_words = [word for word in all_words if word not in english_stop_words]\n",
        "\n",
        "freq_dist = nltk.FreqDist(all_words_except_stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_sTDgdGdyj6"
      },
      "source": [
        "# Podemos visualizar la frecuencia de las palabras más comunes\n",
        "\n",
        "most_common_20 = np.array(list(map(lambda x: list(x), freq_dist.most_common(20))))\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "sns.barplot(x=most_common_20[:, 0],y=most_common_20[:, 1].astype('int'), ax=ax, palette='RdYlBu');\n",
        "ax.set_title('Frecuencia de las 20 palabras más comunes', pad=10)\n",
        "ax.set_ylabel('Count')\n",
        "ax.tick_params(axis='x', rotation=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvK-wbYxdyj6"
      },
      "source": [
        "most_common_50 = np.array(list(map(lambda x: list(x), freq_dist.most_common(50))))\n",
        "\n",
        "fig = plt.figure(figsize=(6, 10))\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "sns.barplot(x=most_common_50[:, 1].astype('int'), y=most_common_50[:, 0], ax=ax, palette='RdYlBu', orient='h');\n",
        "ax.set_title('Frecuencia de las 50 palabras más comunes', pad=10)\n",
        "ax.set_xlabel('Count');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8gOlUZzdyj7"
      },
      "source": [
        "# También podemos visualizar la frecuencia de los bigramas más comunes\n",
        "\n",
        "text = nltk.Text(all_words)\n",
        "freq_dist_bigrams = nltk.FreqDist(list(nltk.bigrams(text)))\n",
        "\n",
        "freq_dist_bigrams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOHtH_Wrdyj7"
      },
      "source": [
        "most_common_20 = np.array(list(map(lambda x: list(x), freq_dist_bigrams.most_common(20))),dtype=object)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "sns.barplot(x=most_common_20[:, 0], y=most_common_20[:, 1], ax=ax, palette='RdYlBu');\n",
        "ax.set_title('Frecuencia de las 20 bigramas más comunes', pad=10)\n",
        "ax.set_ylabel('Count')\n",
        "ax.tick_params(axis='x', rotation=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oSSJX-Xdyj8"
      },
      "source": [
        "# Probemos sin palabras vacías\n",
        "\n",
        "text = nltk.Text(all_words_except_stop_words)\n",
        "freq_dist_bigrams = nltk.FreqDist(list(nltk.bigrams(text)))\n",
        "\n",
        "freq_dist_bigrams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AleYv3Drdyj9"
      },
      "source": [
        "most_common_20 = np.array(list(map(lambda x: list(x), freq_dist_bigrams.most_common(20))),dtype=object)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "sns.barplot(x=most_common_20[:, 0], y=most_common_20[:, 1], ax=ax, palette='RdYlBu');\n",
        "ax.set_title('Frecuencia de las 20 bigramas más comunes sin palabras vacías', pad=10)\n",
        "ax.set_ylabel('Count')\n",
        "ax.tick_params(axis='x', rotation=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkGBaWHqdyj9"
      },
      "source": [
        "# No estamos restringidos solamente a bigramas\n",
        "\n",
        "from nltk.util import ngrams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ran-7OBwdyj-"
      },
      "source": [
        "text = nltk.Text(all_words)\n",
        "freq_dist_trigrams = nltk.FreqDist(list(ngrams(text, 3)))\n",
        "\n",
        "most_common_20 = np.array(list(map(lambda x: list(x), freq_dist_trigrams.most_common(20))),dtype=object)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "sns.barplot(x=most_common_20[:, 0], y=most_common_20[:, 1], ax=ax, palette='RdYlBu');\n",
        "ax.set_title('Frecuencia de las 20 trigramas más comunes con palabras vacías', pad=10)\n",
        "ax.set_ylabel('Count')\n",
        "ax.tick_params(axis='x', rotation=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aphHob5_dyj-"
      },
      "source": [
        "text = nltk.Text(all_words_except_stop_words)\n",
        "freq_dist_trigrams = nltk.FreqDist(list(ngrams(text, 3)))\n",
        "\n",
        "most_common_20 = np.array(list(map(lambda x: list(x), freq_dist_trigrams.most_common(20))),dtype=object)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "sns.barplot(x=most_common_20[:, 0], y=most_common_20[:, 1], ax=ax, palette='RdYlBu');\n",
        "ax.set_title('Frecuencia de las 20 trigramas más comunes sin palabras vacías', pad=10)\n",
        "ax.set_ylabel('Count')\n",
        "ax.tick_params(axis='x', rotation=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YskHV59Sdyj_"
      },
      "source": [
        "# También podemos generar histogramas para visualizar la frecuencia de longitudes de palabras y oraciones\n",
        "\n",
        "word_lengths = [len(w) for w in all_words_except_stop_words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpWS8UxSdyj_"
      },
      "source": [
        "sns.displot(word_lengths, kde=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbFN2OppdykA"
      },
      "source": [
        "sentence_lengths = grouped_by_title.apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAEzdjZudykA"
      },
      "source": [
        "sns.displot(sentence_lengths, kde=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCVKuVnSdykA"
      },
      "source": [
        "num_of_words = grouped_by_title.str.split(' ').str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R_3ZHnLdykB"
      },
      "source": [
        "sns.displot(num_of_words, kde=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCX1iTf0dykC"
      },
      "source": [
        "Para terminar, vamos a hacer una nube de palabras utilizando la librería `wordcloud`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZDPdRxYdykD"
      },
      "source": [
        "from wordcloud import WordCloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQStQWSYdykD"
      },
      "source": [
        "wordcloud = WordCloud(max_font_size=100, background_color=\"white\").generate(' '.join(all_words_except_stop_words))\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApAJxyH2dykE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}